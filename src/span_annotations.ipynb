{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic span annotations\n",
    "\n",
    "We use GPT-4 to automatically annotate the text notes we generated with spans of where each symptom is mentioned in the note. This entails telling GPT-4 the symptoms experienced by the patient, and asking it to extract from the clinical note all phrases that mention these symptoms (whether positive or negative). If the symptom is not mentioned at all in the note, then no phrase should be extracted either. \n",
    "\n",
    "We use a different strategy for the normal notes and for the compact version of these notes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal notes\n",
    "\n",
    "We use the function below to generate the prompt for each note. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/df_synsum.p\", \"rb\") as file: \n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympt_dict = {\"dyspnea\": \"dysp\", \"cough\": \"cough\", \"nasal symptoms\": \"nasal\", \"respiratory pain\": \"pain\", \"fever\": \"fever\"}\n",
    "\n",
    "def generate_prompt(row): \n",
    "\n",
    "    text_note = row[\"text\"]\n",
    "    text_note = text_note.replace(\"\\n\", \" \")\n",
    "\n",
    "    prompt = f\"The following information is known about the patient's symptoms:\\n\"\n",
    "    for sympt, sympt_col_name in sympt_dict.items():  \n",
    "        sympt_val = row[sympt_col_name]\n",
    "        prompt += f\"- {sympt}: {sympt_val}\\n\"\n",
    "    prompt += f\"\\nFollowing the instructions you received, please extract from the following clinical note all phrases (verbatim) that describe these symptoms:\\n\\\"{text_note}\\\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following information is known about the patient's symptoms:\n",
      "- dyspnea: no\n",
      "- cough: no\n",
      "- nasal symptoms: no\n",
      "- respiratory pain: no\n",
      "- fever: high\n",
      "\n",
      "Following the instructions you received, please extract from the following clinical note all phrases (verbatim) that describe these symptoms:\n",
      "\"**History** Patient reports a significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever. There have been no respiratory symptoms such as pain, dyspnea, or cough. The patient illustrates general malaise and mentions feeling very fatigued due to the fever. No notable changes in daily routine or exposure to environments that might typically contribute to fever are reported. Recent stress levels and potential exposure to infectious agents during travels are also discussed.  **Physical Examination** Vital signs show elevated temperature (103 °F). Heart rate is slightly tachycardic at 98 bpm, corresponding with the fever. Oxygen saturation is within normal limits at 98%, and lungs are clear to auscultation without any added sounds. Abdominal examination is normal, without tenderness or organomegaly. Skin shows no rashes, warmth, or lesions. Capillary refill time is adequate. Neurological assessment is non-focal. Overall, there are no evident physical findings to explain the fever apart from the stated temperature elevation.\"\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(df.loc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the system message, we show the LLM the annotation instructions. We explicitly ask the LLM to reply with a json object, so we can easily process the extracted phrases further. The annotations instructions are as follows: \n",
    "\n",
    "---\n",
    "\n",
    "I will show you a clinical note containing information on a patient's symptoms. For each symptom, I will tell you whether the patient suffers from this symptom or not. \n",
    "\n",
    "Your task is to extract phrases from the note that mention these symptoms. The annotation must have the following JSON structure:  \n",
    "[ \n",
    "   {\n",
    "      \"symptom\": one of the symptoms (\"dyspnea\", \"cough\", \"respiratory pain\", \"fever\" or \"nasal symptoms\")\n",
    "      \"text\": phrase in the text that mentions the symptom and whether it is present or absent\n",
    "   }  \n",
    "   {\n",
    "      \"symptom\": ...\n",
    "      \"text\":...\n",
    "   }\n",
    "   ...\n",
    "]\n",
    "\n",
    "Keep the following instructions in mind:  \n",
    "- The same symptom may be mentioned multiple times. Include all phrases in which a symptom is mentioned. Consider both the \"history\" portion of the note, and the \"physical examination\" portion of the note.\n",
    "- Also annotate a symptom if the note mentions that the patient does not suffer from it. \n",
    "- The phrases do not need to be full sentences, but need to be verbatim as they appear in the note. You are not allowed to alter any words. If you leave out words, use ...\n",
    "- Order does not matter.\n",
    "- You will reply only with the JSON itself, and you will not wrap in JSON markers.\n",
    "- You can only extract phrases from the \"clinical note\", not from any of the other text in the prompt. \n",
    "- Not all symptoms are necessarily mentioned in the note. Do not include a symptom in the JSON if you cannot find any implicit or explicit mention of it in the clinical note. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "SYS_MESSAGE_NORMAL = \"\"\"I will show you a clinical note containing information on a patient's symptoms. For each symptom, I will tell you whether the patient suffers from this symptom or not. \n",
    "\n",
    "Your task is to extract phrases from the note that mention these symptoms. The annotation must have the following JSON structure:  \n",
    "[ \n",
    "   {\n",
    "      \"symptom\": one of the symptoms (\"dyspnea\", \"cough\", \"respiratory pain\", \"fever\" or \"nasal symptoms\")\n",
    "      \"text\": phrase in the text that mentions the symptom and whether it is present or absent\n",
    "   }  \n",
    "   {\n",
    "      \"symptom\": ...\n",
    "      \"text\":...\n",
    "   }\n",
    "   ...\n",
    "]\n",
    "\n",
    "Keep the following instructions in mind:  \n",
    "- The same symptom may be mentioned multiple times. Include all phrases in which a symptom is mentioned. Consider both the \"history\" portion of the note, and the \"physical examination\" portion of the note.\n",
    "- Also annotate a symptom if the note mentions that the patient does not suffer from it. \n",
    "- The phrases do not need to be full sentences, but need to be verbatim as they appear in the note. You are not allowed to alter any words. If you leave out words, use ...\n",
    "- Order does not matter.\n",
    "- You will reply only with the JSON itself, and you will not wrap in JSON markers.\n",
    "- You can only extract phrases from the \"clinical note\", not from any of the other text in the prompt. \n",
    "- Not all symptoms are necessarily mentioned in the note. Do not include a symptom in the JSON if you cannot find any implicit or explicit mention of it in the clinical note. \n",
    "\"\"\"\n",
    "\n",
    "def prompt_GPT_full(row, compl=\"normal\"): \n",
    "\n",
    "   messages = []\n",
    "   system_message = {\"role\": \"system\", \"content\": SYS_MESSAGE_NORMAL}\n",
    "   messages.append(system_message)\n",
    "\n",
    "   messages.append({\"role\": \"user\", \"content\": generate_prompt(row)})\n",
    "   res = openai.chat.completions.create(\n",
    "      model = \"gpt-4o\", \n",
    "      temperature = 0.2, \n",
    "      max_tokens = 2048,\n",
    "      messages = messages\n",
    "    )\n",
    "   response = res.choices[0].message.content # response\n",
    "\n",
    "   return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = prompt_GPT_full(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   {\n",
      "      \"symptom\": \"fever\",\n",
      "      \"text\": \"a significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever\"\n",
      "   },\n",
      "   {\n",
      "      \"symptom\": \"fever\",\n",
      "      \"text\": \"feeling very fatigued due to the fever\"\n",
      "   },\n",
      "   {\n",
      "      \"symptom\": \"fever\",\n",
      "      \"text\": \"Vital signs show elevated temperature (103 °F)\"\n",
      "   },\n",
      "   {\n",
      "      \"symptom\": \"fever\",\n",
      "      \"text\": \"corresponding with the fever\"\n",
      "   },\n",
      "   {\n",
      "      \"symptom\": \"fever\",\n",
      "      \"text\": \"there are no evident physical findings to explain the fever apart from the stated temperature elevation\"\n",
      "   },\n",
      "   {\n",
      "      \"symptom\": \"dyspnea\",\n",
      "      \"text\": \"There have been no respiratory symptoms such as pain, dyspnea, or cough\"\n",
      "   },\n",
      "   {\n",
      "      \"symptom\": \"cough\",\n",
      "      \"text\": \"There have been no respiratory symptoms such as pain, dyspnea, or cough\"\n",
      "   },\n",
      "   {\n",
      "      \"symptom\": \"respiratory pain\",\n",
      "      \"text\": \"There have been no respiratory symptoms such as pain, dyspnea, or cough\"\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "resp = json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that the LLM often hallucinates phrases that are actually not present in the note. We therefore process the responses by matching the phrases with the text. We use some regex matching to ensure that capital letters and punctuation don't form an issue. We also check whether the symptoms are named correctly in the JSON response (to ensure that the LLM is not extracting additional hallucinated symptoms). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def complete_annotations(ann_obj, compl, filter_empty=True): \n",
    "\n",
    "    completed_annotations = {}\n",
    "    failed_attempts = {}\n",
    "\n",
    "    for i, phrases in ann_obj.items():\n",
    "\n",
    "        # retrieve note\n",
    "        if compl == \"normal\":\n",
    "            note = df.loc[int(i), \"text\"]\n",
    "        elif compl == \"adv\": \n",
    "            note = df.loc[int(i), \"advanced_text\"]\n",
    "        \n",
    "        # find start and end character of phrase in the note\n",
    "        # if simple regex fixes don't manage to find the phrase, we put the annotation aside for later\n",
    "        for entry in phrases:\n",
    "\n",
    "            phrase = entry[\"text\"]\n",
    "\n",
    "            if (len(phrase) != 0) or not filter_empty: # empty phrases are filtered out later\n",
    "                start_idx = note.find(phrase) # check the note for the full phrase\n",
    "\n",
    "                if start_idx == -1: \n",
    "                    regex_pattern = re.escape(phrase).replace(r'\\.\\.\\.', r'.+?') # replace \"...\" with a regex pattern that matches any characters\n",
    "                    regex_pattern = re.sub(r'\\\\ ', r'\\\\W*', regex_pattern)  # allow optional punctuation where spaces exist\n",
    "                    match = re.search(regex_pattern, note, re.IGNORECASE) # ignore capital letters\n",
    "                    if match: \n",
    "                        start_idx = match.start()\n",
    "                        end_idx = match.end()\n",
    "                    elif i not in failed_attempts: \n",
    "                        end_idx = -1\n",
    "                        failed_attempts[i] = phrases\n",
    "                else: \n",
    "                    end_idx = start_idx + len(phrase)\n",
    "\n",
    "                entry[\"start\"] = start_idx\n",
    "                entry[\"end\"] = end_idx\n",
    "\n",
    "                # check if symptoms have the correct names \n",
    "                if entry[\"symptom\"] not in [\"dyspnea\", \"cough\", \"respiratory pain\", \"fever\", \"nasal symptoms\"]: \n",
    "                    failed_attempts[i] = phrases\n",
    "\n",
    "                if i not in failed_attempts:\n",
    "                    new_phrase = note[start_idx:end_idx]\n",
    "                    entry[\"text\"] = new_phrase # make sure the phrase exactly corresponds to what is found in the text\n",
    "\n",
    "        if i not in failed_attempts:\n",
    "            if filter_empty:\n",
    "                completed_annotations[i] = [entry for entry in phrases if len(entry[\"text\"]) != 0] # leave out phrases that are empty (\"\")\n",
    "            else: \n",
    "                completed_annotations[i] = phrases\n",
    "            \n",
    "    return completed_annotations, failed_attempts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann, failed = complete_annotations({\"0\": resp}, compl=\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [{'symptom': 'fever',\n",
       "   'text': 'a significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever',\n",
       "   'start': 28,\n",
       "   'end': 143},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'feeling very fatigued due to the fever',\n",
       "   'start': 271,\n",
       "   'end': 309},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'Vital signs show elevated temperature (103 °F)',\n",
       "   'start': 556,\n",
       "   'end': 602},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'corresponding with the fever',\n",
       "   'start': 650,\n",
       "   'end': 678},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'there are no evident physical findings to explain the fever apart from the stated temperature elevation',\n",
       "   'start': 985,\n",
       "   'end': 1088},\n",
       "  {'symptom': 'dyspnea',\n",
       "   'text': 'There have been no respiratory symptoms such as pain, dyspnea, or cough',\n",
       "   'start': 145,\n",
       "   'end': 216},\n",
       "  {'symptom': 'cough',\n",
       "   'text': 'There have been no respiratory symptoms such as pain, dyspnea, or cough',\n",
       "   'start': 145,\n",
       "   'end': 216},\n",
       "  {'symptom': 'respiratory pain',\n",
       "   'text': 'There have been no respiratory symptoms such as pain, dyspnea, or cough',\n",
       "   'start': 145,\n",
       "   'end': 216}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records for which at least one of the phrases was not able to be matched to the text, go into the \"failed\" set. The other records receive \"start\" and \"end\" index annotations, indicating where the phrase can be found in the note.\n",
    "\n",
    "Here, the \"failed\" set is empty. For the sake of showing what would happen to failed records, we adapt our correct annotation to a partially incorrect one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp[0][\"text\"] = \"an increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann, failed = complete_annotations({\"0\": resp}, compl=\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [{'symptom': 'fever',\n",
       "   'text': 'an increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever',\n",
       "   'start': -1,\n",
       "   'end': -1},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'feeling very fatigued due to the fever',\n",
       "   'start': 271,\n",
       "   'end': 309},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'Vital signs show elevated temperature (103 °F)',\n",
       "   'start': 556,\n",
       "   'end': 602},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'corresponding with the fever',\n",
       "   'start': 650,\n",
       "   'end': 678},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'there are no evident physical findings to explain the fever apart from the stated temperature elevation',\n",
       "   'start': 985,\n",
       "   'end': 1088},\n",
       "  {'symptom': 'dyspnea',\n",
       "   'text': 'There have been no respiratory symptoms such as pain, dyspnea, or cough',\n",
       "   'start': 145,\n",
       "   'end': 216},\n",
       "  {'symptom': 'cough',\n",
       "   'text': 'There have been no respiratory symptoms such as pain, dyspnea, or cough',\n",
       "   'start': 145,\n",
       "   'end': 216},\n",
       "  {'symptom': 'respiratory pain',\n",
       "   'text': 'There have been no respiratory symptoms such as pain, dyspnea, or cough',\n",
       "   'start': 145,\n",
       "   'end': 216}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the phrase which could not be found in the text has start and end index -1. \n",
    "\n",
    "Due to the large number of notes, we cannot edit all these mistakes manually. We therefore constructed a second prompt that asks the LLM to correct these phrases to phrases that can actually be found in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_MESSAGE = \"\"\"I will show you a clinical note, together with one or more phrases that were extracted from it. However, some mistakes were made in extracting these phrases. You must correct them.\"\"\"\n",
    "\n",
    "def create_phrase_string(phrases): \n",
    "    str_format = \"\"\n",
    "    for phrase in phrases: \n",
    "        str_format += f\"- {phrase}\\n\"\n",
    "    return str_format\n",
    "\n",
    "def correcting_prompt(note, extracted_phrases): \n",
    "    \n",
    "    messages = []\n",
    "    system_message = {\"role\": \"system\", \"content\": SYS_MESSAGE}\n",
    "    messages.append(system_message)\n",
    "\n",
    "    note = note.replace(\"\\n\", \" \")\n",
    "    user_msg = f\"The following is a clinical note:\\n{note}\\n\\n\"\n",
    "    user_msg += \"The following phrases were extracted from this note. However, they do not exactly match the text:\\n\"\n",
    "    user_msg += create_phrase_string(extracted_phrases)\n",
    "    user_msg += f\"\\n\\nPlease correct the phrases so they map exactly to a phrase in the text. \"\n",
    "    user_msg += \"\"\"You must reply with the following JSON format: \n",
    "{\n",
    "   original phrase: corrected phrase\n",
    "}\n",
    "\n",
    "You will reply only with the JSON itself, and you will not wrap in JSON markers.\"\"\"\n",
    "\n",
    "    print(user_msg)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "    res = openai.chat.completions.create(\n",
    "        model = \"gpt-4o\", \n",
    "        temperature = 0.2, \n",
    "        max_tokens = 2048,\n",
    "        messages = messages\n",
    "        )\n",
    "    \n",
    "    response = res.choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a clinical note:\n",
      "**History** Patient reports a significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever. There have been no respiratory symptoms such as pain, dyspnea, or cough. The patient illustrates general malaise and mentions feeling very fatigued due to the fever. No notable changes in daily routine or exposure to environments that might typically contribute to fever are reported. Recent stress levels and potential exposure to infectious agents during travels are also discussed.  **Physical Examination** Vital signs show elevated temperature (103 °F). Heart rate is slightly tachycardic at 98 bpm, corresponding with the fever. Oxygen saturation is within normal limits at 98%, and lungs are clear to auscultation without any added sounds. Abdominal examination is normal, without tenderness or organomegaly. Skin shows no rashes, warmth, or lesions. Capillary refill time is adequate. Neurological assessment is non-focal. Overall, there are no evident physical findings to explain the fever apart from the stated temperature elevation.\n",
      "\n",
      "The following phrases were extracted from this note. However, they do not exactly match the text:\n",
      "- an increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever\n",
      "\n",
      "\n",
      "Please correct the phrases so they map exactly to a phrase in the text. You must reply with the following JSON format: \n",
      "{\n",
      "   original phrase: corrected phrase\n",
      "}\n",
      "\n",
      "You will reply only with the JSON itself, and you will not wrap in JSON markers.\n"
     ]
    }
   ],
   "source": [
    "idx = \"0\"\n",
    "wrong_phrases = set([phrase[\"text\"] for phrase in failed[idx] if phrase[\"start\"] == -1])\n",
    "note = df.loc[int(idx), \"text\"]\n",
    "response = correcting_prompt(note, wrong_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"an increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever\": \"a significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check again with the complete_annotations function whether the phrase can be found in the note. In this case, it can be, so the phrase is corrected. This was the case for the majority of incorrectly extracted phrases. There was a small set of notes (around 10) that were not able to be corrected this way, so we corrected them manually. \n",
    "\n",
    "The final span annotations for the normal notes can be found in \"data/spans/normal_span_annotations.json\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/spans/normal_span_annotations.json\", \"r\") as file:\n",
    "    ann = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'symptom': 'fever',\n",
       "  'text': 'mild fever onset over the past two days',\n",
       "  'start': 28,\n",
       "  'end': 67},\n",
       " {'symptom': 'fever',\n",
       "  'text': 'Temperature: 37.8°C (low-grade fever)',\n",
       "  'start': 436,\n",
       "  'end': 473},\n",
       " {'symptom': 'respiratory pain',\n",
       "  'text': 'notable respiratory pain primarily during deep inspiration and chest movements',\n",
       "  'start': 78,\n",
       "  'end': 156},\n",
       " {'symptom': 'cough',\n",
       "  'text': 'The patient denies any cough',\n",
       "  'start': 158,\n",
       "  'end': 186},\n",
       " {'symptom': 'dyspnea',\n",
       "  'text': 'The patient denies any cough or dyspnea',\n",
       "  'start': 158,\n",
       "  'end': 197},\n",
       " {'symptom': 'nasal symptoms',\n",
       "  'text': 'The patient reports no recent travel, sick contacts, or changes in routine that could explain the symptoms',\n",
       "  'start': 302,\n",
       "  'end': 408}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann[\"5623\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**History** Patient reports mild fever onset over the past two days. There is notable respiratory\n",
      "pain primarily during deep inspiration and chest movements. The patient denies any cough or dyspnea.\n",
      "It is stated that regular activities have become uncomfortable due to the persistent chest\n",
      "discomfort. The patient reports no recent travel, sick contacts, or changes in routine that could\n",
      "explain the symptoms.  **Physical Examination** Temperature: 37.8°C (low-grade fever). Lungs\n",
      "auscultated with clear breath sounds and no adventitious sounds. Chest palpation reveals tenderness\n",
      "in the costal region without any apparent soft tissue swelling. Respirations are regular, with no\n",
      "signs of labored or distressed breathing. Vital signs: blood pressure 120/80 mmHg, heart rate 76\n",
      "bpm, respiratory rate 16 breaths per minute. Cardiovascular examination is unremarkable. Skin: warm\n",
      "and dry, no rash or lesions.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(df.loc[5623, \"text\"], 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced notes\n",
    "\n",
    "The advanced notes proved more challenging to make the LLM accurately extract symptom spans from scratch. So, we decided to start from the phrases extracted from the normal note, and ask the LLM to match these to phrases in the advanced note. \n",
    "\n",
    "The system instructions are as follows.\n",
    "\n",
    "---\n",
    "\n",
    "I will show you two versions of a clinical note. The first version describes a patient's visit to the doctor's office. The second one describes the same visit, but in a more compact style (using abbreviations and shortcuts), while preserving the overall message. \n",
    "\n",
    "I will show you a set of phrases which were extracted from the first version of the note. Your task is to map these to phrases in the second version of the note. \n",
    "\n",
    "You must reply with the following JSON format.\n",
    "{\n",
    "   phrase in version 1 : corresponding phrase extracted in version 2\n",
    "}\n",
    "\n",
    "Keep the following instructions in mind: \n",
    "- Please extract phrases verbatim. \n",
    "- Please use the empty string if you cannot find a phrase with the same meaning.\n",
    "- The phrases you extract must have the same meaning, you cannot simply copy phrases that are in the same spot in the text.\n",
    "- You will reply only with the JSON itself, and you will not wrap in JSON markers.\n",
    "\n",
    "---\n",
    "\n",
    "The full prompt is created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phrase_string(phrases):\n",
    "    list_str = \"[\\n\"\n",
    "    sel_phrases = []\n",
    "    for phrase in phrases: \n",
    "        sent = phrase[\"text\"]\n",
    "        if sent not in sel_phrases: # only include each phrase once\n",
    "            sel_phrases.append(sent)\n",
    "            list_str += f\"\\\"{sent}\\\",\\n\"\n",
    "    list_str = list_str[:-2]\n",
    "    list_str += \"\\n]\"\n",
    "    return list_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_MESSAGE_ADV = \"\"\"I will show you two versions of a clinical note. The first version describes a patient's visit to the doctor's office. The second one describes the same visit, but in a more compact style (using abbreviations and shortcuts), while preserving the overall message. \n",
    "\n",
    "I will show you a set of phrases which were extracted from the first version of the note. Your task is to map these to phrases in the second version of the note. \n",
    "\n",
    "You must reply with the following JSON format.\n",
    "{\n",
    "   phrase in version 1 : corresponding phrase extracted in version 2\n",
    "}\n",
    "\n",
    "Keep the following instructions in mind: \n",
    "- Please extract phrases verbatim. \n",
    "- Please use the empty string if you cannot find a phrase with the same meaning.\n",
    "- The phrases you extract must have the same meaning, you cannot simply copy phrases that are in the same spot in the text.\n",
    "- You will reply only with the JSON itself, and you will not wrap in JSON markers.\n",
    "\"\"\"\n",
    "\n",
    "def prompt_GPT_advanced(note_ver1, note_ver2, phrases): \n",
    "\n",
    "   if len(phrases) == 0: \n",
    "      return \"{}\" # if no phrases to be extracted, don't prompt the LLM\n",
    "\n",
    "   messages = []\n",
    "   system_message = {\"role\": \"system\", \"content\": SYS_MESSAGE_ADV}\n",
    "   messages.append(system_message)\n",
    "\n",
    "   note_ver1 = note_ver1.replace(\"\\n\", \" \")\n",
    "   note_ver2 = note_ver2.replace(\"\\n\", \" \")\n",
    "   user_msg = f\"Clinical note, version 1:\\n{note_ver1}\\n\\n\"\n",
    "   user_msg += \"Extracted phrases:\\n\"\n",
    "   user_msg += create_phrase_string(phrases)\n",
    "   user_msg += f\"\\n\\nPlease extract the equivalent phrases from the second version of the note.\\n\\nClinical note, version 2:\\n{note_ver2}\"\n",
    "\n",
    "   print(user_msg)\n",
    "\n",
    "   messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "   res = openai.chat.completions.create(\n",
    "      model = \"gpt-4o\", \n",
    "      temperature = 0.2, \n",
    "      max_tokens = 2048,\n",
    "      messages = messages\n",
    "    )\n",
    "   first_response = res.choices[0].message.content\n",
    "   messages.append({\"role\": \"assistant\", \"content\": first_response}) # add response of assistant to chat history\n",
    "\n",
    "   # additional check\n",
    "   check_msg = \"Please check if each extracted phrase has the same meaning as the original phrase. If not, substitute it by the empty string (\"\"). The rest of the JSON must remain unchanged.\"\n",
    "   messages.append({\"role\": \"user\", \"content\": check_msg})\n",
    "\n",
    "   res = openai.chat.completions.create(\n",
    "      model = \"gpt-4o\", \n",
    "      temperature = 0.2, \n",
    "      max_tokens = 2048,\n",
    "      messages = messages\n",
    "    )\n",
    "   final_response = res.choices[0].message.content\n",
    "\n",
    "   return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical note, version 1:\n",
      "**History** Patient reports a significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever. There have been no respiratory symptoms such as pain, dyspnea, or cough. The patient illustrates general malaise and mentions feeling very fatigued due to the fever. No notable changes in daily routine or exposure to environments that might typically contribute to fever are reported. Recent stress levels and potential exposure to infectious agents during travels are also discussed.  **Physical Examination** Vital signs show elevated temperature (103 °F). Heart rate is slightly tachycardic at 98 bpm, corresponding with the fever. Oxygen saturation is within normal limits at 98%, and lungs are clear to auscultation without any added sounds. Abdominal examination is normal, without tenderness or organomegaly. Skin shows no rashes, warmth, or lesions. Capillary refill time is adequate. Neurological assessment is non-focal. Overall, there are no evident physical findings to explain the fever apart from the stated temperature elevation.\n",
      "\n",
      "Extracted phrases:\n",
      "[\n",
      "\"significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever\",\n",
      "\"feeling very fatigued due to the fever\",\n",
      "\"Vital signs show elevated temperature (103 °F)\",\n",
      "\"corresponding with the fever\",\n",
      "\"There have been no respiratory symptoms such as pain, dyspnea, or cough\"\n",
      "]\n",
      "\n",
      "Please extract the equivalent phrases from the second version of the note.\n",
      "\n",
      "Clinical note, version 2:\n",
      "**History** Pt reports high fever for 48 hrs, denies resp pain, dyspnea, or cough. Describes significant fatigue and malaise. No recent routine changes or known infectious exposures. Discusses recent stress and travel.  **Physical Examination** VS: Temp 103 °F, HR 98 bpm (tachycardic), O2 sat 98%. Lungs clear, no adventitious sounds. Abd: non-tender, no organomegaly. Skin: no rashes/lesions, normal CRT. Neuro: non-focal. Overall: WNL apart from elevated fever.\n"
     ]
    }
   ],
   "source": [
    "normal_note = df.loc[0, \"text\"]\n",
    "adv_note = df.loc[0, \"advanced_text\"]\n",
    "extracted_phrases = ann[\"0\"]\n",
    "response = prompt_GPT_advanced(normal_note, adv_note, extracted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"significant increase in body temperature over the last 48 hours, exceeding normal ranges, indicating a high fever\": \"Pt reports high fever for 48 hrs\",\n",
      "   \"feeling very fatigued due to the fever\": \"Describes significant fatigue and malaise\",\n",
      "   \"Vital signs show elevated temperature (103 °F)\": \"VS: Temp 103 °F\",\n",
      "   \"corresponding with the fever\": \"\",\n",
      "   \"There have been no respiratory symptoms such as pain, dyspnea, or cough\": \"denies resp pain, dyspnea, or cough\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since the advanced note is more compact, it sometimes leaves out phrases. In this case \"corresponding with the fever\" was extracted from the normal note, but could not be matched with any phrase in the advanced note (since it is simply not there). When there is only one such case, we simply remove it from the annotations. When there are more than one such cases for a particular note, we try again with another LLM call (see further). \n",
    "\n",
    "Once we have these matched phrase pairs, we can go through the spans extracted from the normal note again, and see if we have a matched pair. Upfront, it seemed like a possibility that the phrase extracted from the normal note might be altered by the LLM in its response, making it impossible to find a match. However, in practice, we saw that this never happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_advanced_note(normal_ann, responses):\n",
    "\n",
    "    adv_ann = {}\n",
    "    failed = {}\n",
    "    for i in responses: \n",
    "        orig_phrases = normal_ann[i]\n",
    "        adv_phrases = responses[i]\n",
    "        adv_entries = []\n",
    "        for entry in orig_phrases: \n",
    "            phrase = entry[\"text\"]\n",
    "            try: \n",
    "                matched_phrase = adv_phrases[phrase]\n",
    "            except: \n",
    "                # decide what to do when phrase cannot be matched exactly\n",
    "                # look for similar phrase using regex \n",
    "                print(\"no exact match found!\")\n",
    "                matched_phrase = \"\"\n",
    "                failed[i] = adv_phrases\n",
    "\n",
    "            adv_entries.append({\"symptom\": entry[\"symptom\"], \"text\": matched_phrase})\n",
    "        adv_ann[i] = adv_entries\n",
    "\n",
    "    return adv_ann, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ann, failed = annotate_advanced_note({\"0\": ann[\"0\"]}, {\"0\": resp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [{'symptom': 'fever', 'text': 'Pt reports high fever for 48 hrs'},\n",
       "  {'symptom': 'fever', 'text': 'Describes significant fatigue and malaise'},\n",
       "  {'symptom': 'fever', 'text': 'VS: Temp 103 °F'},\n",
       "  {'symptom': 'fever', 'text': ''},\n",
       "  {'symptom': 'dyspnea', 'text': 'denies resp pain, dyspnea, or cough'},\n",
       "  {'symptom': 'cough', 'text': 'denies resp pain, dyspnea, or cough'},\n",
       "  {'symptom': 'respiratory pain',\n",
       "   'text': 'denies resp pain, dyspnea, or cough'}]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we then try to match the phrases extracted from the advanced note with the text. If a phrase cannot be matched, the annotation is added to the batch of failed notes, and we correct the phrase using the same prompt we used for the normal notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ann, failed = complete_annotations(adv_ann, compl=\"adv\", filter_empty=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [{'symptom': 'fever',\n",
       "   'text': 'Pt reports high fever for 48 hrs',\n",
       "   'start': 12,\n",
       "   'end': 44},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'Describes significant fatigue and malaise',\n",
       "   'start': 83,\n",
       "   'end': 124},\n",
       "  {'symptom': 'fever', 'text': 'VS: Temp 103 °F', 'start': 245, 'end': 260},\n",
       "  {'symptom': 'fever', 'text': '', 'start': 0, 'end': 0},\n",
       "  {'symptom': 'dyspnea',\n",
       "   'text': 'denies resp pain, dyspnea, or cough',\n",
       "   'start': 46,\n",
       "   'end': 81},\n",
       "  {'symptom': 'cough',\n",
       "   'text': 'denies resp pain, dyspnea, or cough',\n",
       "   'start': 46,\n",
       "   'end': 81},\n",
       "  {'symptom': 'respiratory pain',\n",
       "   'text': 'denies resp pain, dyspnea, or cough',\n",
       "   'start': 46,\n",
       "   'end': 81}]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, we keep track of the annotations for which no match could be found in the advanced note. If there are two or more such cases in the same note, we try to fix them with an additional LLM call. Instead of using the original annotations found in the normal note, and matching them with the advanced note, we ask the LLM to extract symptom phrases from the advanced note directly. By way of example, we adapt the annotations in our example so they fall in this category. Imagine the LLM did not find the denial of pain, dyspnea and cough in the advanced note: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ann[\"0\"][4][\"text\"] = \"\"\n",
    "adv_ann[\"0\"][5][\"text\"] = \"\"\n",
    "adv_ann[\"0\"][6][\"text\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the prompt to correct these cases. The system instructions are the following: \n",
    "\n",
    "---\n",
    "\n",
    "I will show you a clinical note containing information on a patient's symptoms. For each symptom, I will tell you whether the patient suffers from this symptom or not. \n",
    "\n",
    "You will get to see phrases that have been extracted from the note, describing some of these symptoms. This input will have the following JSON structure:\n",
    "[ \n",
    "   {\n",
    "      \"symptom\": one of the symptoms (\"dyspnea\", \"cough\", \"respiratory pain\", \"fever\" or \"nasal symptoms\")\n",
    "      \"text\": phrase in the text that mentions the symptom and whether it is present or absent\n",
    "   }  \n",
    "   {\n",
    "      \"symptom\": ...\n",
    "      \"text\":...\n",
    "   }\n",
    "   ...\n",
    "]\n",
    "\n",
    "Some phrases have not been filled in yet (indicated by \"?\" in the \"text\" field). Your task is to fill in this phrases, leaving the rest of the JSON and its structure untouched.\n",
    "\n",
    "Keep the following instructions in mind:  \n",
    "- Also annotate a symptom if the note mentions that the patient does not suffer from it. \n",
    "- The phrases do not need to be full sentences, but need to be verbatim as they appear in the note. You are not allowed to alter any words. If you leave out words, use ...\n",
    "- You will reply only with the JSON itself, and you will not wrap in JSON markers.\n",
    "- You can only extract phrases from the \"clinical note\", not from any of the other text in the prompt. \n",
    "- Not all symptoms are necessarily mentioned in the note. Simply fill in \"\" if you cannot find any implicit or explicit mention of it in the clinical note. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_JSON_str(phrases):\n",
    "    list_str = \"[\\n\"\n",
    "    for phrase in phrases: \n",
    "        sent = phrase[\"text\"]\n",
    "        sympt = phrase[\"symptom\"]\n",
    "        if len(sent) == 0:\n",
    "            list_str += f\"   {{\\\"symptom\\\":\\\"{sympt}\\\", \\\"text\\\": \\\"?\\\"}},\\n\"\n",
    "        else: \n",
    "            list_str += f\"   {{\\\"symptom\\\":\\\"{sympt}\\\", \\\"text\\\": \\\"{sent}\\\"}},\\n\"\n",
    "    list_str = list_str[:-2]\n",
    "    list_str += \"\\n]\"\n",
    "    return list_str\n",
    "\n",
    "SYS_MESSAGE_CORR = \"\"\"I will show you a clinical note containing information on a patient's symptoms. For each symptom, I will tell you whether the patient suffers from this symptom or not. \n",
    "\n",
    "You will get to see phrases that have been extracted from the note, describing some of these symptoms. This input will have the following JSON structure:\n",
    "[ \n",
    "   {\n",
    "      \"symptom\": one of the symptoms (\"dyspnea\", \"cough\", \"respiratory pain\", \"fever\" or \"nasal symptoms\")\n",
    "      \"text\": phrase in the text that mentions the symptom and whether it is present or absent\n",
    "   }  \n",
    "   {\n",
    "      \"symptom\": ...\n",
    "      \"text\":...\n",
    "   }\n",
    "   ...\n",
    "]\n",
    "\n",
    "Some phrases have not been filled in yet (indicated by \"?\" in the \"text\" field). Your task is to fill in this phrases, leaving the rest of the JSON and its structure untouched.\n",
    "\n",
    "Keep the following instructions in mind:  \n",
    "- Also annotate a symptom if the note mentions that the patient does not suffer from it. \n",
    "- The phrases do not need to be full sentences, but need to be verbatim as they appear in the note. You are not allowed to alter any words. If you leave out words, use ...\n",
    "- You will reply only with the JSON itself, and you will not wrap in JSON markers.\n",
    "- You can only extract phrases from the \"clinical note\", not from any of the other text in the prompt. \n",
    "- Not all symptoms are necessarily mentioned in the note. Simply fill in \"\" if you cannot find any implicit or explicit mention of it in the clinical note. \n",
    "\"\"\"\n",
    "\n",
    "sympt_dict = {\"dyspnea\": \"dysp\", \"cough\": \"cough\", \"nasal symptoms\": \"nasal\", \"respiratory pain\": \"pain\", \"fever\": \"fever\"}\n",
    "\n",
    "def prompt_GPT_advanced_corrected(row, phrases): \n",
    "\n",
    "   if len(phrases) == 0: \n",
    "      return \"{}\" # if no phrases to be extracted, don't prompt the LLM\n",
    "\n",
    "   messages = []\n",
    "   system_message = {\"role\": \"system\", \"content\": SYS_MESSAGE_CORR}\n",
    "   messages.append(system_message)\n",
    "\n",
    "   note_adv = row[\"advanced_text\"].replace(\"\\n\", \" \")\n",
    "\n",
    "   user_msg = f\"The following information is known about the patient's symptoms:\\n\"\n",
    "   for sympt, sympt_col_name in sympt_dict.items():  \n",
    "      sympt_val = row[sympt_col_name]\n",
    "      user_msg += f\"- {sympt}: {sympt_val}\\n\"\n",
    "   \n",
    "   user_msg += f\"\\n Following the instructions you received, please extract from the following clinical note all phrases (verbatim) that describe these symptoms:\\n{note_adv}\\n\\n\"\n",
    "   user_msg += \"Please fill in the missing text (indicated with \\\"?\\\"). If you cannot find any mention of a symptom, simply fill in \\\"\\\".\\n\"\n",
    "   user_msg += create_JSON_str(phrases)\n",
    "\n",
    "   print(user_msg)\n",
    "   \n",
    "   messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "   res = openai.chat.completions.create(\n",
    "      model = \"gpt-4o\", \n",
    "      temperature = 0.2, \n",
    "      max_tokens = 2048,\n",
    "      messages = messages\n",
    "    )\n",
    "   response = res.choices[0].message.content\n",
    "\n",
    "   return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following information is known about the patient's symptoms:\n",
      "- dyspnea: no\n",
      "- cough: no\n",
      "- nasal symptoms: no\n",
      "- respiratory pain: no\n",
      "- fever: high\n",
      "\n",
      " Following the instructions you received, please extract from the following clinical note all phrases (verbatim) that describe these symptoms:\n",
      "**History** Pt reports high fever for 48 hrs, denies resp pain, dyspnea, or cough. Describes significant fatigue and malaise. No recent routine changes or known infectious exposures. Discusses recent stress and travel.  **Physical Examination** VS: Temp 103 °F, HR 98 bpm (tachycardic), O2 sat 98%. Lungs clear, no adventitious sounds. Abd: non-tender, no organomegaly. Skin: no rashes/lesions, normal CRT. Neuro: non-focal. Overall: WNL apart from elevated fever.\n",
      "\n",
      "Please fill in the missing text (indicated with \"?\"). If you cannot find any mention of a symptom, simply fill in \"\".\n",
      "[\n",
      "   {\"symptom\":\"fever\", \"text\": \"Pt reports high fever for 48 hrs\"},\n",
      "   {\"symptom\":\"fever\", \"text\": \"Describes significant fatigue and malaise\"},\n",
      "   {\"symptom\":\"fever\", \"text\": \"VS: Temp 103 °F\"},\n",
      "   {\"symptom\":\"fever\", \"text\": \"?\"},\n",
      "   {\"symptom\":\"dyspnea\", \"text\": \"?\"},\n",
      "   {\"symptom\":\"cough\", \"text\": \"?\"},\n",
      "   {\"symptom\":\"respiratory pain\", \"text\": \"?\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "response = prompt_GPT_advanced_corrected(df.loc[0], adv_ann[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   {\"symptom\":\"fever\", \"text\": \"Pt reports high fever for 48 hrs\"},\n",
      "   {\"symptom\":\"fever\", \"text\": \"Describes significant fatigue and malaise\"},\n",
      "   {\"symptom\":\"fever\", \"text\": \"VS: Temp 103 °F\"},\n",
      "   {\"symptom\":\"fever\", \"text\": \"Overall: WNL apart from elevated fever\"},\n",
      "   {\"symptom\":\"dyspnea\", \"text\": \"denies resp pain, dyspnea, or cough\"},\n",
      "   {\"symptom\":\"cough\", \"text\": \"denies resp pain, dyspnea, or cough\"},\n",
      "   {\"symptom\":\"respiratory pain\", \"text\": \"denies resp pain, dyspnea, or cough\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ann[\"0\"] = resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM was able to extract the phrases pointing towards these symptoms now. We then use the \"complete_annotations\" function like before to complete the annotations. For the failed notes, the phrases that could not be found in the text are corrected with an additional LLM call (as before). We now remove the empty annotations, since it's now likely that they really were not mentioned in the advanced note. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ann, failed = complete_annotations(adv_ann, compl=\"adv\", filter_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [{'symptom': 'fever',\n",
       "   'text': 'Pt reports high fever for 48 hrs',\n",
       "   'start': 12,\n",
       "   'end': 44},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'Describes significant fatigue and malaise',\n",
       "   'start': 83,\n",
       "   'end': 124},\n",
       "  {'symptom': 'fever', 'text': 'VS: Temp 103 °F', 'start': 245, 'end': 260},\n",
       "  {'symptom': 'fever',\n",
       "   'text': 'Overall: WNL apart from elevated fever',\n",
       "   'start': 425,\n",
       "   'end': 463},\n",
       "  {'symptom': 'dyspnea',\n",
       "   'text': 'denies resp pain, dyspnea, or cough',\n",
       "   'start': 46,\n",
       "   'end': 81},\n",
       "  {'symptom': 'cough',\n",
       "   'text': 'denies resp pain, dyspnea, or cough',\n",
       "   'start': 46,\n",
       "   'end': 81},\n",
       "  {'symptom': 'respiratory pain',\n",
       "   'text': 'denies resp pain, dyspnea, or cough',\n",
       "   'start': 46,\n",
       "   'end': 81}]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we delete duplicates from the annotations (exact same symptom and exact same phrase). This then leaves us with the full annotations for the advanced notes, of which an example is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/spans/adv_span_annotations.json\", \"r\") as file:\n",
    "    ann = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'symptom': 'dyspnea', 'text': 'no dyspnea', 'start': 110, 'end': 120},\n",
       " {'symptom': 'cough', 'text': 'no dyspnea or cough', 'start': 110, 'end': 129},\n",
       " {'symptom': 'nasal symptoms',\n",
       "  'text': 'No notable PMHx of resp illnesses or chronic conditions.',\n",
       "  'start': 285,\n",
       "  'end': 341},\n",
       " {'symptom': 'respiratory pain',\n",
       "  'text': 'sharp resp pain during deep breaths',\n",
       "  'start': 73,\n",
       "  'end': 108},\n",
       " {'symptom': 'respiratory pain',\n",
       "  'text': 'Pain localized to lower right thorax, worsens with movement or cough.',\n",
       "  'start': 131,\n",
       "  'end': 200},\n",
       " {'symptom': 'fever',\n",
       "  'text': 'sudden onset of high fever x 2 days',\n",
       "  'start': 23,\n",
       "  'end': 58},\n",
       " {'symptom': 'fever', 'text': 'Temp 39.2°C', 'start': 368, 'end': 379}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann[\"8596\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**History** Pt reports mild fever onset x 2 days. Notable respiratory pain w/ deep inspiration &\n",
      "chest movements. Denies cough or dyspnea. Stated regular activities uncomfortable due to chest\n",
      "discomfort. No recent travel, sick contacts, or routine changes explained.  **Physical Examination**\n",
      "Temp: 37.8°C (low-grade fever). Lungs: clear breath sounds, no adventitious sounds. Chest: tender on\n",
      "costal palp, no soft tissue swelling. Regular respirations, no labored breathing. Vitals: BP 120/80\n",
      "mmHg, HR 76 bpm, RR 16 bpm. CV exam unremarkable. Skin: warm, dry, no rash/lesions.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(df.loc[5623, \"advanced_text\"], 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality evaluation\n",
    "\n",
    "We manually evaluated 100 randomly selected notes. The results can be found in \"eval/spans/span_eval_results.xlsx\", with \"eval/spans/span_eval_dataset.txt\" containing the subset of notes we evaluated. \n",
    "\n",
    "We went over every note (normal and compact versions) and annotated the following: \n",
    "- missing phrases: how many additional phrases mentioning a symptom were found in the text, that were not extracted by the LLM\n",
    "- incorrect phrases: how many of the phrases extracted by the LLM were incorrect\n",
    "\n",
    "These metrics allow us to calculate precision (how many phrases are correct, over the total number of extracted phrases per note) and recall (how many correct phrases are recovered, over the total number of correct phrases). The total number of correct phrases is the sum of the correct phrases (the extracted phrases minus the incorrect phrases) and the phrases that were missed. \n",
    "\n",
    "We calculate precision and recall for every note, and then average them at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eval = pd.read_csv(\"../eval/spans/span_eval_results.csv\", sep=\";\", header=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.columns = [\"note_idx\", \"missing_normal\", \"incorrect_normal\", \"missing_adv\", \"incorrect_adv\"]\n",
    "eval.set_index(\"note_idx\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"../data/spans/normal_span_annotations.json\", \"r\") as file: \n",
    "    ann_normal = json.load(file)\n",
    "with open(f\"../data/spans/adv_span_annotations.json\", \"r\") as file: \n",
    "    ann_adv = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the total number of extracted phrases for each note. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in eval.iterrows(): \n",
    "    eval.loc[idx, \"n_phrases_normal\"] = len(ann_normal[str(idx)])\n",
    "    eval.loc[idx, \"n_phrases_adv\"] = len(ann_adv[str(idx)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate precision and recall for each note. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prec(row, suffix=\"normal\"): \n",
    "\n",
    "    n_incorrect = row[f\"incorrect_{suffix}\"] # number of phrases that were incorrectly extracted (false positives)\n",
    "    n_extracted = row[f\"n_phrases_{suffix}\"] # number of phrases that were extracted (true positives + false positives)\n",
    "\n",
    "    if n_extracted != 0:\n",
    "        precision = 1 - n_incorrect/n_extracted # 1 - false negatives/(true positives + false negatives)\n",
    "    else: \n",
    "        precision = 1\n",
    "\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall(row, suffix=\"normal\"): \n",
    "    \n",
    "    n_incorrect = row[f\"incorrect_{suffix}\"] # number of phrases that were incorrectly extracted (false positives)\n",
    "    n_missing = row[f\"missing_{suffix}\"] # number of phrases that were missed (false negatives)\n",
    "    n_extracted = row[f\"n_phrases_{suffix}\"] # number of phrases that were extracted (true positives + false positives)\n",
    "\n",
    "    n_correct = n_extracted - n_incorrect # number of phrases that were correctly extracted (true positives)\n",
    "    if n_correct < 0: \n",
    "        print(f\"uh oh! {row.name}\")\n",
    "    n_total = n_correct + n_missing # number of phrases that should have been extracted (true positives + false negatives)\n",
    "\n",
    "    if n_total != 0:\n",
    "        recall = n_correct/n_total # true positives/(true positives + false negatives)\n",
    "    else: \n",
    "        recall = 1\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval[\"precision_normal\"] = eval.apply(calc_prec, axis=1, args=(\"normal\",))\n",
    "eval[\"recall_normal\"] = eval.apply(calc_recall, axis=1, args=(\"normal\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval[\"precision_adv\"] = eval.apply(calc_prec, axis=1, args=(\"adv\",))\n",
    "eval[\"recall_adv\"] = eval.apply(calc_recall, axis=1, args=(\"adv\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_normal</th>\n",
       "      <th>precision_adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.940643</td>\n",
       "      <td>0.935536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision_normal  precision_adv\n",
       "mean          0.940643       0.935536"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.describe().loc[[\"mean\"], [\"precision_normal\", \"precision_adv\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_normal</th>\n",
       "      <th>recall_adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.98781</td>\n",
       "      <td>0.945036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recall_normal  recall_adv\n",
       "mean        0.98781    0.945036"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.describe().loc[[\"mean\"], [\"recall_normal\", \"recall_adv\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "We calculate some statistics on the spans, such as in how many spans a symptom is found, or how long the spans are on average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"../data/df_synsum.p\", \"rb\") as file: \n",
    "    df = pickle.load(file)\n",
    "df = df[[\"dysp\", \"cough\", \"pain\", \"fever\", \"nasal\", \"text\", \"advanced_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a pre-processing step, we calculate the number of spans extracted per symptom, for every note. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympt_dict = {\"dysp\": \"dyspnea\", \"cough\": \"cough\", \"nasal\": \"nasal symptoms\", \"pain\": \"respiratory pain\", \"fever\": \"fever\"}\n",
    "def count_sympt(row, ann, sympt): \n",
    "    n = 0\n",
    "    spans = ann[str(row.name)]\n",
    "    for span in spans: \n",
    "        if span[\"symptom\"] == sympt_dict[sympt]:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "for sympt in sympt_dict:  \n",
    "    df[f\"count_{sympt}\"] = df.apply(count_sympt, axis=1, args=(ann_normal, sympt,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of spans per symptom, per note, on average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of spans per note for dysp: 0.96\n",
      "Average # of spans per note for cough: 1.03\n",
      "Average # of spans per note for nasal: 0.85\n",
      "Average # of spans per note for pain: 0.52\n",
      "Average # of spans per note for fever: 0.79\n",
      "Average # of spans per note: 4.16\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict:\n",
    "    n = df[f\"count_{sympt}\"].mean()\n",
    "    print(f\"Average # of spans per note for {sympt}: {n:.2f}\")\n",
    "n = (df[\"count_dysp\"]+df[\"count_cough\"]+df[\"count_pain\"]+df[\"count_fever\"]+df[\"count_nasal\"]).mean()\n",
    "print(f\"Average # of spans per note: {n:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of symptoms over all extracted spans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perc. of spans belonging to dysp: 23.16%\n",
      "Perc. of spans belonging to cough: 24.90%\n",
      "Perc. of spans belonging to nasal: 20.35%\n",
      "Perc. of spans belonging to pain: 12.59%\n",
      "Perc. of spans belonging to fever: 19.01%\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict:\n",
    "    n = df[f\"count_{sympt}\"].sum()\n",
    "    n_total = (df[\"count_dysp\"]+df[\"count_cough\"]+df[\"count_pain\"]+df[\"count_fever\"]+df[\"count_nasal\"]).sum()\n",
    "    print(f\"Perc. of spans belonging to {sympt}: {n/n_total*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How long are the spans on average?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def count_avg_length(ann, sympt):\n",
    "    char_len = []\n",
    "    word_len = []\n",
    "    for i in ann: \n",
    "        spans = ann[i]\n",
    "        for span in spans: \n",
    "            if (sympt is None) or (span[\"symptom\"] == sympt_dict[sympt]):\n",
    "                words = span[\"text\"].split(\" \")\n",
    "                char_len.append(len(span[\"text\"]))\n",
    "                word_len.append(len(words))\n",
    "    return np.mean(char_len), np.mean(word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dysp avg number of words: 8.34, avg number of chars: 57.21\n",
      "cough avg number of words: 8.83, avg number of chars: 56.70\n",
      "nasal avg number of words: 8.92, avg number of chars: 63.05\n",
      "pain avg number of words: 9.34, avg number of chars: 63.54\n",
      "fever avg number of words: 7.04, avg number of chars: 44.82\n",
      "avg number of words: 8.46, avg number of chars: 56.71\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict:\n",
    "    char_len, word_len = count_avg_length(ann_normal, sympt)\n",
    "    print(f\"{sympt} avg number of words: {word_len:.2f}, avg number of chars: {char_len:.2f}\")\n",
    "char_len, word_len = count_avg_length(ann_normal, None)\n",
    "print(f\"avg number of words: {word_len:.2f}, avg number of chars: {char_len:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What percentage of spans is found in the history portion of the note? What percentage is found in the physical examination portion of the note?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/emb/df_train_emb_part1.p\", \"rb\") as file:\n",
    "    df_emb_train1 = pickle.load(file)\n",
    "with open(\"../data/emb/df_train_emb_part2.p\", \"rb\") as file:\n",
    "    df_emb_train2 = pickle.load(file)\n",
    "df_train = pd.concat([df_emb_train1, df_emb_train2])\n",
    "with open(\"../data/emb/df_test_emb.p\", \"rb\") as file:\n",
    "    df_test = pickle.load(file)\n",
    "df = pd.merge(df, df_train[[\"text_hist\", \"text_phys_exam\", \"advanced_text_hist\", \"advanced_text_phys_exam\"]], how=\"left\", left_index=True, right_index=True)\n",
    "df.loc[df_test.index, \"text_hist\"] = df_test[\"text_hist\"]\n",
    "df.loc[df_test.index, \"text_phys_exam\"] = df_test[\"text_phys_exam\"]\n",
    "df.loc[df_test.index, \"advanced_text_hist\"] = df_test[\"advanced_text_hist\"]\n",
    "df.loc[df_test.index, \"advanced_text_phys_exam\"] = df_test[\"advanced_text_phys_exam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hist_phys(ann, df, sympt, compl): \n",
    "    n_hist = 0\n",
    "    n_phys = 0\n",
    "    if compl == \"normal\": \n",
    "        text_hist = df[\"text_hist\"]\n",
    "        text_phys = df[\"text_phys_exam\"]\n",
    "    else: \n",
    "        text_hist = df[\"advanced_text_hist\"]\n",
    "        text_phys = df[\"advanced_text_phys_exam\"]\n",
    "    for i in ann: \n",
    "        for span in ann[i]:\n",
    "            if (sympt is None) or span[\"symptom\"] == sympt_dict[sympt]:\n",
    "                if span[\"text\"] in text_hist.loc[int(i)]: \n",
    "                    n_hist += 1\n",
    "                elif span[\"text\"] in text_phys.loc[int(i)]: \n",
    "                    n_phys += 1\n",
    "                else: \n",
    "                    print(f\"uh oh! {i}\")\n",
    "    return n_hist, n_phys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dysp span found in hist: 79.30%, dysp span found in phys: 20.70%\n",
      "cough span found in hist: 91.54%, cough span found in phys: 8.46%\n",
      "nasal span found in hist: 63.03%, nasal span found in phys: 36.97%\n",
      "pain span found in hist: 81.57%, pain span found in phys: 18.43%\n",
      "fever span found in hist: 65.87%, fever span found in phys: 34.13%\n",
      "span found in hist: 76.77%, span found in phys: 23.23%\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict: \n",
    "    n_hist, n_phys = count_hist_phys(ann_normal, df, sympt, \"normal\")\n",
    "    print(f\"{sympt} span found in hist: {n_hist/(n_hist+n_phys)*100:.2f}%, {sympt} span found in phys: {n_phys/(n_hist+n_phys)*100:.2f}%\")\n",
    "n_hist, n_phys = count_hist_phys(ann_normal, df, None, \"normal\")\n",
    "print(f\"span found in hist: {n_hist/(n_hist+n_phys)*100:.2f}%, span found in phys: {n_phys/(n_hist+n_phys)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional on whether a symptom is present in the patient, how often is it mentioned in the note?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perc mentioned for dysp=yes: 99.05%\n",
      "Perc mentioned for cough=yes: 96.97%\n",
      "Perc mentioned for nasal=yes: 95.66%\n",
      "Perc mentioned for pain=yes: 81.72%\n",
      "Perc mentioned for fever=low: 71.60%\n",
      "Perc mentioned for fever=high: 95.89%\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict:\n",
    "    if sympt != \"fever\":\n",
    "        df_subset = df[df[sympt] == \"yes\"]\n",
    "        perc = len(df_subset[df_subset[f\"count_{sympt}\"] != 0])/len(df_subset)\n",
    "        print(f\"Perc mentioned for {sympt}=yes: {perc*100:.2f}%\")\n",
    "sympt = \"fever\"\n",
    "df_subset = df[df[sympt] == \"low\"]\n",
    "perc = len(df_subset[df_subset[f\"count_{sympt}\"] != 0])/len(df_subset)\n",
    "print(f\"Perc mentioned for {sympt}=low: {perc*100:.2f}%\")\n",
    "sympt = \"fever\"\n",
    "df_subset = df[df[sympt] == \"high\"]\n",
    "perc = len(df_subset[df_subset[f\"count_{sympt}\"] != 0])/len(df_subset)\n",
    "print(f\"Perc mentioned for {sympt}=high: {perc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perc mentioned for dysp=no: 66.54%\n",
      "Perc mentioned for cough=no: 64.48%\n",
      "Perc mentioned for nasal=no: 26.55%\n",
      "Perc mentioned for pain=no: 39.91%\n",
      "Perc mentioned for fever=none: 44.44%\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict:\n",
    "    if sympt != \"fever\":\n",
    "        df_subset = df[df[sympt] == \"no\"]\n",
    "        perc = len(df_subset[df_subset[f\"count_{sympt}\"] != 0])/len(df_subset)\n",
    "        print(f\"Perc mentioned for {sympt}=no: {perc*100:.2f}%\")\n",
    "sympt = \"fever\"\n",
    "df_subset = df[df[sympt] == \"none\"]\n",
    "perc = len(df_subset[df_subset[f\"count_{sympt}\"] != 0])/len(df_subset)\n",
    "print(f\"Perc mentioned for {sympt}=none: {perc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional on whether it is present in a patient, how many times is a symptom mentioned in a note on average?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# times mentioned when dysp=yes: 2.03\n",
      "# times mentioned when cough=yes: 1.78\n",
      "# times mentioned when nasal=yes: 2.47\n",
      "# times mentioned when pain=yes: 1.28\n",
      "# times mentioned when fever=low: 1.55\n",
      "# times mentioned when fever=high: 2.46\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict:\n",
    "    if sympt != \"fever\":\n",
    "        df_subset = df[df[sympt] == \"yes\"]\n",
    "        perc = df_subset[f\"count_{sympt}\"].mean()\n",
    "        print(f\"# times mentioned when {sympt}=yes: {perc:.2f}\")\n",
    "sympt = \"fever\"\n",
    "df_subset = df[df[sympt] == \"low\"]\n",
    "perc = df_subset[f\"count_{sympt}\"].mean()\n",
    "print(f\"# times mentioned when {sympt}=low: {perc:.2f}\")\n",
    "sympt = \"fever\"\n",
    "df_subset = df[df[sympt] == \"high\"]\n",
    "perc = df_subset[f\"count_{sympt}\"].mean()\n",
    "print(f\"# times mentioned when {sympt}=high: {perc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# times mentioned when dysp=no: 0.70\n",
      "# times mentioned when cough=no: 0.65\n",
      "# times mentioned when nasal=no: 0.30\n",
      "# times mentioned when pain=no: 0.40\n",
      "# times mentioned when fever=none: 0.52\n"
     ]
    }
   ],
   "source": [
    "for sympt in sympt_dict:\n",
    "    if sympt != \"fever\":\n",
    "        df_subset = df[df[sympt] == \"no\"]\n",
    "        perc = df_subset[f\"count_{sympt}\"].mean()\n",
    "        print(f\"# times mentioned when {sympt}=no: {perc:.2f}\")\n",
    "sympt = \"fever\"\n",
    "df_subset = df[df[sympt] == \"none\"]\n",
    "perc = df_subset[f\"count_{sympt}\"].mean()\n",
    "print(f\"# times mentioned when {sympt}=none: {perc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many notes have no spans at all?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# notes where no symptom is mentioned at all: 1628 (16.28%)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for i in ann_normal: \n",
    "    spans = ann_normal[i]\n",
    "    if len(spans) == 0: \n",
    "        n += 1\n",
    "print(f\"# notes where no symptom is mentioned at all: {n} ({n/10000*100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-run the code above for the compact notes as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bn-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
